{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python2.7\n",
    "\n",
    "import argparse\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "import gzip\n",
    "\n",
    "#sys.path.append(\"/san/melissa/workspace/str-qtl/lmm/\")\n",
    "#from LMMSimulationsUtils2 import *\n",
    "\n",
    "\"\"\"\n",
    "Analyze heritability of gene expression due to SNPs/STRs\n",
    "Notes:\n",
    "** The reported SE for STRs when treating the STR as fixed effect are the SE on *beta*, not on *beta^2* **\n",
    "\"\"\"\n",
    "\n",
    "GCTA_MIN_VE = 0.000001 # Lowest VE that GCTA reports when constrained\n",
    "\n",
    "def PROGRESS(msg, printit=True):\n",
    "    if printit: # false for some messages when not in debug mode\n",
    "        sys.stderr.write(\"%s\\n\"%msg.strip())\n",
    "\n",
    "def GetMAF(x):\n",
    "    \"\"\"\n",
    "    Get SNP MAF\n",
    "    \"\"\"\n",
    "    x=x.convert_objects(convert_numeric=True)\n",
    "    vals = x.values\n",
    "#    print(len(vals))\n",
    "    maf = sum(vals)*1.0/(2*len(vals))\n",
    "    return min([maf, 1-maf])\n",
    "\n",
    "def GRM(snpdata):\n",
    "    \"\"\"\n",
    "    Return n by n GRM, scaled to have mean diagonal element 1\n",
    "    \"\"\"\n",
    "#    snpdata.apply(pd.to_numeric, errors='coerce')\n",
    "    p, n = snpdata.shape\n",
    "    print(p,'  ',n)\n",
    "    K = np.zeros((n, n))\n",
    "    for i in range(p):\n",
    "#        print(snpdata.iloc[i,:])\n",
    "        gt = snpdata.iloc[i,:].apply(lambda x: float(x))\n",
    "        var = np.var(gt)\n",
    "        #print(var)\n",
    "        if var == 0: continue\n",
    "        m = np.mean(gt)\n",
    "        x = np.reshape((np.array(gt)-m).transpose(), (n, 1))\n",
    "        gt_m = 1/(var*p)*x.dot(x.transpose())\n",
    "        K = K + gt_m\n",
    "#    print(K )\n",
    "    # Make sure diagonal had mean 1 (should anyway)\n",
    "    diag_mean = np.mean(np.diagonal(K))\n",
    "#    print(np.diagonal(K))\n",
    "    K = K/diag_mean\n",
    "    return K\n",
    "\n",
    "def WriteGCTAPhenotypeFile(locus, exprfile):\n",
    "    \"\"\"\n",
    "    Write the phenotype file \n",
    "    \"\"\"\n",
    "    n=len(locus)\n",
    "    f = open(exprfile, \"w\")\n",
    "    for i in range(n):\n",
    "        f.write(' '.join([str(i),str(i),str(locus[i]),'\\n']))\n",
    "    f.close()\n",
    "\n",
    "def WriteGCTAGRM(K, grmfile, p):\n",
    "    \"\"\"\n",
    "    Calculate GRM and output file in GCTA format (.gz)\n",
    "    Need to write:\n",
    "    $grmfile.grm.gz: ind1, ind2, num nonmissing SNPs, relatedness (space-separated) (indices start at 1, rows into $grmfile.ind)\n",
    "      only includes lower triangle of GRM\n",
    "    $grmfile.ind: family ID, individual ID (space-separated)\n",
    "    \"\"\"\n",
    "    n = K.shape[0]\n",
    "    # Calculate GRM\n",
    "    f = gzip.open(\"%s.grm.gz\"%grmfile, \"wb\")\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            val = K[i, j]\n",
    "#it was     f.write(\" \".join(map(str, [j+1, i+1, p, val]))+\"\\n\")\n",
    "            f.write(bytes(\" \".join(map(str, [j+1, i+1, p, val]))+\"\\n\" , 'UTF-8'))\n",
    "    f.close()\n",
    "    # Write ind file\n",
    "    f = open(\"%s.grm.id\"%grmfile, \"w\")\n",
    "    for i in range(n):\n",
    "        f.write(\" \".join(map(str, [i, i]))+\"\\n\")\n",
    "    f.close()\n",
    "\n",
    "def ParseGCTAResults(gctafile, include_str):\n",
    "    \"\"\"\n",
    "    return cis_snp_h2, cis_snp_h2_se, cis_str_h2, cis_str_h2_se, logL\n",
    "    \"\"\"\n",
    "    f = open(gctafile, \"r\")\n",
    "    lines = f.readlines()\n",
    "    cis_str_h2 = None\n",
    "    cis_str_h2_se = None\n",
    "    for line in lines:\n",
    "        items = line.strip().split()\n",
    "        if len(items) < 1: continue\n",
    "        if include_str == \"NO\" or include_str == \"FE\" or include_str == \"SAMPLES\":\n",
    "            if items[0] == \"V(G)\":\n",
    "                cis_snp_h2 = items[1]\n",
    "                cis_snp_h2_se = items[2]\n",
    "        else:\n",
    "            if items[0] == \"V(G1)\":\n",
    "                cis_snp_h2 = items[1]\n",
    "                cis_snp_h2_se = items[2]\n",
    "            if items[0] == \"V(G2)\":\n",
    "                cis_str_h2 = items[1]\n",
    "                cis_str_h2_se = items[2]\n",
    "        if items[0] == \"logL\":\n",
    "            logL = items[1]\n",
    "        if include_str == \"FE\":\n",
    "            if items[0] == \"Fix_eff\":\n",
    "                ind = lines.index(line)+2\n",
    "                items = lines[ind].strip().split()\n",
    "                cis_str_h2 = float(items[0])**2\n",
    "                cis_str_h2_se = items[1]\n",
    "        if items[0] == \"Pval\":\n",
    "            Pval = items[1]\n",
    "    if include_str == \"FE\":\n",
    "        return cis_snp_h2, cis_snp_h2_se, cis_str_h2, cis_str_h2_se, logL, Pval\n",
    "    else:\n",
    "        return cis_snp_h2, cis_snp_h2_se, cis_str_h2, cis_str_h2_se, logL, 'N/A'\n",
    "\n",
    "def GetPermutedLocusSTRs(locus_str):\n",
    "    \"\"\"\n",
    "    Return locus_str dataframe with STR genotypes permuted\n",
    "    \"\"\"\n",
    "    gts = list(locus_str.iloc[:,0])\n",
    "    random.shuffle(gts)\n",
    "    locus_str_perm = pd.DataFrame({locus_str.columns[0]: gts})\n",
    "    locus_str_perm.index = locus_str.index\n",
    "    return locus_str_perm\n",
    "\n",
    "def z(vals):\n",
    "    vals = list(map(float, list(vals)))\n",
    "    m = np.mean(vals)\n",
    "    s = math.sqrt(np.var(vals))\n",
    "    return [(item-m)*1.0/s for item in vals]\n",
    "\n",
    "def ZNorm(locus_vars):\n",
    "    \"\"\"\n",
    "    Znormalize variants\n",
    "    \"\"\"\n",
    "    columns = locus_vars.columns\n",
    "    for c in columns:\n",
    "        locus_vars[c] = z(locus_vars[c])\n",
    "    return locus_vars\n",
    "\n",
    "\n",
    "def WriteGCTACovarFile(locus, strcovarfile):\n",
    "    \"\"\" Write GCTA covariable file using normalized genotype\n",
    "    \"\"\"\n",
    "    f = open(strcovarfile, \"w\")\n",
    "    n=locus.shape[0]\n",
    "    for i in range(n):\n",
    "        N_geno = list(locus.iloc[i,:].values)\n",
    "        f.write(\" \".join([str(i), str(i)]+[str(m) for m in N_geno])+\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T = ['WholeBlood','Cells-Transformedfibroblasts','Muscle-Skeletal','Lung','Adipose-Subcutaneous','Artery-Tibial','Esophagus-Mucosa']\n",
    "BASEDIR = \"/storage/szfeupe/Runs/650GTEx_estr/Analysis_by_Tissue/\"\n",
    "SNPS = \"/storage/szfeupe/Runs/650GTEx_estr/SNP_Analysis/\"\n",
    "STRS = \"/storage/szfeupe/Runs/650GTEx_estr/Genotypes/STR_Norm_lized_Geno.table\"\n",
    "GENO = pd.read_csv(STRS, sep='\\t',low_memory=False)\n",
    "#Gene_table = pd.read_csv('/storage/szfeupe/Runs/GTEx_estr/FEATURES/Genes_only_table', sep='\\t')\n",
    "\n",
    "tissue = T[4]\n",
    "EXPRFILE = BASEDIR+tissue+\"/Corr_Expr.csv\"\n",
    "EXPRANNOTFILE = '/storage/resources/dbase/human/hg19/gencode_gene_annotations_hg19.csv'\n",
    "CHROM = \"chr1\"\n",
    "REML_NO_CONSTRAIN=True\n",
    "DISTFROMGENE = 10000\n",
    "STRGTFILE = STRS\n",
    "SNPGTFILE = \"/storage/szfeupe/Runs/650GTEx_estr/SNP_Analysis/chr1.tab\"\n",
    "OUTFILE = 'here'\n",
    "SNPMAF = 0.05\n",
    "LMM_METHOD = \"GCTA\"\n",
    "INCLUDE_STR = \"FE\"\n",
    "ESTR_RESULTS_FILE = \"/storage/szfeupe/Runs/650GTEx_estr/Analysis_by_Tissue/\"+tissue+\"/PQValues\"\n",
    "ESTR_GENES_ONLY = 0.1\n",
    "UNLINKED_CTRL=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.4/site-packages/ipykernel/__main__.py:12: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "/usr/lib64/python3.4/site-packages/pandas/core/indexing.py:1367: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    }
   ],
   "source": [
    "# Load expression and annotation\n",
    "expr = pd.read_csv(EXPRFILE,sep=',' ,low_memory=False) \n",
    "expr_annot = pd.read_csv(EXPRANNOTFILE,low_memory=False )\n",
    "expr_annot.index = expr_annot[\"probe.id\"].values\n",
    "# Load SNP genotypes\n",
    "snpgt = pd.read_csv(SNPGTFILE, sep=\"\\t\",  low_memory=False)\n",
    "# Load STR genotypes\n",
    "strgt = pd.read_csv(STRGTFILE, sep=\"\\t\",low_memory=False)\n",
    "strgt = strgt.loc[strgt['chrom']==CHROM]\n",
    "# Restrict to STR samples\n",
    "str_samples = list(set(strgt.columns[2:].values).intersection(set(snpgt.columns[2:].values)))\n",
    "expr = expr.loc[str_samples,:]\n",
    "snpgt = snpgt[[\"chrom\",\"start\"] + str_samples]\n",
    "strgt = strgt[[\"chrom\",\"start\"] + str_samples]\n",
    "# Load STR results\n",
    "estr_results = pd.read_csv(ESTR_RESULTS_FILE, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for ENSG00000159445.8\n",
      "Linked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.4/site-packages/ipykernel/__main__.py:32: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use Series.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SNP_151836675', 'SNP_151836824', 'SNP_151837283', 'SNP_151838066',\n",
      "       'SNP_151838092', 'SNP_151838723', 'SNP_151839838', 'SNP_151840085',\n",
      "       'SNP_151841165', 'SNP_151841424', 'SNP_151841525', 'SNP_151841770',\n",
      "       'SNP_151842485', 'SNP_151842679', 'SNP_151844396', 'SNP_151844650',\n",
      "       'SNP_151845569', 'SNP_151845650', 'SNP_151845713', 'SNP_151846059',\n",
      "       'SNP_151846517', 'SNP_151846719', 'SNP_151847126', 'SNP_151847180',\n",
      "       'SNP_151847193', 'SNP_151847870', 'SNP_151848126', 'SNP_151850072',\n",
      "       'SNP_151851456', 'SNP_151852017', 'SNP_151853278', 'SNP_151853754',\n",
      "       'SNP_151854076', 'SNP_151855156', 'SNP_151856953', 'SNP_151857431',\n",
      "       'SNP_151858888', 'SNP_151858926', 'SNP_151859050', 'SNP_151859153',\n",
      "       'SNP_151859166', 'SNP_151860063', 'SNP_151861477', 'SNP_151862296',\n",
      "       'SNP_151862661', 'SNP_151863001', 'SNP_151864267', 'SNP_151865234',\n",
      "       'SNP_151865439', 'SNP_151865780', 'SNP_151867560', 'SNP_151868098',\n",
      "       'SNP_151868892', 'SNP_151870384', 'SNP_151871309', 'SNP_151871476',\n",
      "       'SNP_151872754', 'SNP_151874385', 'SNP_151874420', 'SNP_151875372',\n",
      "       'SNP_151875388', 'SNP_151875841', 'SNP_151876073', 'SNP_151876367',\n",
      "       'SNP_151876978', 'SNP_151877582', 'SNP_151877655', 'SNP_151878223',\n",
      "       'SNP_151879253', 'SNP_151879613', 'SNP_151879676', 'SNP_151879761',\n",
      "       'SNP_151879799', 'SNP_151879939', 'SNP_151880387', 'SNP_151880870',\n",
      "       'SNP_151881093', 'SNP_151881885', 'SNP_151882826', 'SNP_151882856',\n",
      "       'SNP_151883273', 'SNP_151883303', 'SNP_151883406', 'SNP_151883551',\n",
      "       'SNP_151884287', 'SNP_151884499', 'SNP_151884573', 'SNP_151884636',\n",
      "       'SNP_151885840', 'SNP_151889447', 'SNP_151889988', 'SNP_151890958',\n",
      "       'SNP_151891825', 'SNP_151892199', 'SNP_151892226'],\n",
      "      dtype='object', name='start')  cis SNPs\n",
      "93    609\n",
      "chr1\tENSG00000159445.8\t151913866\t93\t0.294477\t0.259818\t0.018945870735999997\t0.105957\t-109.719\t609\t0.0005227\n",
      "\n"
     ]
    }
   ],
   "source": [
    "UNLINKED_CTRL=False\n",
    "REML_NO_CONSTRAIN=False\n",
    "ESTR_GENES_ONLY = 1\n",
    "genelist = ['ENSG00000159445.8']\n",
    "expr_annot = expr_annot.loc[genelist]\n",
    "estr_results = estr_results.loc[estr_results['gene'].isin(genelist)]\n",
    "expr = expr[genelist]\n",
    "\n",
    "# For each gene, pull out data and perform specified method\n",
    "for i in range(expr_annot.shape[0]):\n",
    "    gene = expr_annot.index.values[i]\n",
    "    ensgene = expr_annot[\"gene.id\"].values[i]\n",
    "    print(\"Getting data for %s\"%gene)\n",
    "    genedir ='/home/szfeupe/projects/GTEX_eSTRs/'\n",
    "    start = expr_annot[\"gene.start\"].values[i]\n",
    "    end = expr_annot[\"gene.stop\"].values[i]\n",
    "# Pull out STRs\n",
    "    samples_to_keep = str_samples\n",
    "    best_str_start = None\n",
    "    if INCLUDE_STR != \"NO\":\n",
    "        try:\n",
    "            if UNLINKED_CTRL:\n",
    "                print('unlinked')\n",
    "                possible_starts = list(strgt[(strgt[\"start\"] >= (start-DISTFROMGENE)) & (strgt[\"start\"] <= (end+DISTFROMGENE))].start)\n",
    "                best_str_start = random.sample(possible_starts, 1)[0]\n",
    "            else:\n",
    "                print('Linked')\n",
    "# make sure to match on Ensembl gene (gene is ILMN if using array)\n",
    "                best_str_start = estr_results[estr_results[\"gene\"]==ensgene].sort_values(\"p.wald\")[\"str.start\"].values[0]\n",
    "        except:\n",
    "            print(\"[%s]\\tERROR: couldn't find STR LMM results\"%gene)\n",
    "            continue\n",
    "        try:\n",
    "            cis_strs = strgt[(strgt[\"start\"] >= (start-DISTFROMGENE)) & (strgt[\"start\"] <= (end+DISTFROMGENE))]\n",
    "            locus_str = cis_strs[samples_to_keep].transpose()\n",
    "            locus_str = strgt[(strgt[\"start\"] == best_str_start)].iloc[[0],:][str_samples].transpose()\n",
    "        except:\n",
    "            print(\"[%s]\\tERROR: couldn't find STR genotypes for position %s\"%(gene, best_str_start))\n",
    "            continue\n",
    "        locus_str.index = str_samples\n",
    "        locus_str.columns = [\"STR_%s\"%best_str_start]\n",
    "        ###So far we only choose the best str as fixed effect.But we should consider all cis STRs \n",
    "        samples_to_keep = [str_samples[k] for k in range(len(str_samples)) if str(locus_str.iloc[:,0].values[k]) != \"None\"]\n",
    "        locus_str = locus_str.loc[samples_to_keep,:]\n",
    "# Make sure STRs are normalized\n",
    "        try:\n",
    "            locus_str = ZNorm(locus_str)\n",
    "        except:\n",
    "            print(\"[%s]\\tERROR: couldn't Z normalize STR genotypes\"%(gene))\n",
    "            continue\n",
    "    # Pull out SNPs\n",
    "    cis_snps = snpgt[(snpgt[\"start\"] >= (start-DISTFROMGENE)) & (snpgt[\"start\"] <= (end+DISTFROMGENE))]\n",
    "    locus_snp = cis_snps[samples_to_keep].transpose()\n",
    "    locus_snp.index = samples_to_keep\n",
    "    locus_snp = locus_snp.dropna(axis=1, how='any')\n",
    "    locus_snp.columns = cis_snps[\"start\"].apply(lambda x: \"SNP_%s\"%x)\n",
    "    locus_snp_maf = locus_snp.apply(lambda x: GetMAF(x), 0)\n",
    "    print(locus_snp.columns, ' cis SNPs')\n",
    "#    \n",
    "#    if len(locus_snp_maf) == 0:\n",
    "#        continue    \n",
    "#    \n",
    "#    locus_snp = locus_snp.loc[:,[i for i in range(len(locus_snp_maf)) if locus_snp_maf[i]>=SNPMAF]]\n",
    "    if locus_snp.shape[1] == 0:\n",
    "        print(\"[%s]\\tERROR: no common SNPs in region\"%gene)\n",
    "        continue\n",
    "# Get expression\n",
    "    y = pd.DataFrame({\"expr\":list(expr.loc[:,gene])})\n",
    "    y.index = str_samples\n",
    "    locus_y = y.loc[samples_to_keep,[\"expr\"]]\n",
    "# Z normalize\n",
    "    locus_y = (locus_y - np.mean(locus_y))/math.sqrt(np.var(locus_y))\n",
    "# Make SNP GRM\n",
    "    locus_snp=locus_snp.apply(pd.to_numeric, errors='coerce')\n",
    "    locus_snp = locus_snp.dropna(axis=1, how='any')\n",
    "    K = GRM(locus_snp.transpose())\n",
    "    if str(np.mean(K)) == \"nan\":\n",
    "        print(\"[%s]\\tERROR: nans in GRM\"%gene)\n",
    "\n",
    "# Write GRM\n",
    "    if LMM_METHOD == \"GCTA\":\n",
    "        exprfile = os.path.join(genedir, \"expr.pheno\")\n",
    "        mgrmfile = os.path.join(genedir, \"mgrm.txt\")\n",
    "        snpgrmfile = os.path.join(genedir, \"snp.grm.txt\")\n",
    "        if REML_NO_CONSTRAIN:\n",
    "            reml_command = \"--reml-no-constrain\"\n",
    "        else: reml_command = \"--reml\"\n",
    "        gcta_cmd = \"/storage/resources/source/gcta64 %s --mgrm-gz %s --pheno %s --out %s/gcta \"%(reml_command, mgrmfile, exprfile, genedir)\n",
    "        g = open(mgrmfile, \"w\")\n",
    "        g.write(snpgrmfile+\"\\n\")\n",
    "        WriteGCTAGRM(K, snpgrmfile, p=locus_snp.shape[1])\n",
    "        if INCLUDE_STR == \"FE\": # --qcovar\n",
    "            strcovarfile = os.path.join(genedir, \"str.qcovar\")\n",
    "            WriteGCTACovarFile(locus_str, strcovarfile)\n",
    "            gcta_cmd += \" --qcovar %s --reml-est-fix\"%strcovarfile\n",
    "        if INCLUDE_STR == \"RE\":\n",
    "            K_str = GRM(locus_str.transpose())\n",
    "            strgrmfile = os.path.join(genedir, \"str.grm.txt\")\n",
    "            g.write(strgrmfile+\"\\n\")\n",
    "            WriteGCTAGRM(K_str, strgrmfile, p=locus_str.shape[1])\n",
    "        g.close()\n",
    "        locus_y[\"expr\"].fillna(\"NA\", inplace=True)\n",
    "        WriteGCTAPhenotypeFile(locus_y[\"expr\"].values, exprfile)\n",
    "        gcta_cmd += \" > /dev/null 2>&1\"\n",
    "        os.system(gcta_cmd)\n",
    "# Parse results\n",
    "        gctafile = os.path.join(genedir, \"gcta.hsq\")\n",
    "        if not os.path.exists(gctafile):\n",
    "            print(\"[%s]\\tERROR: GCTA could not analyze this gene\"%gene)\n",
    "            continue\n",
    "        cis_snp_h2, cis_snp_h2_se, cis_str_h2, cis_str_h2_se, logL, pval = ParseGCTAResults(gctafile, INCLUDE_STR)\n",
    "        # Output results\n",
    "        if INCLUDE_STR == \"NO\" or INCLUDE_STR == \"SAMPLES\":\n",
    "            word=\"\\t\".join(map(str, [CHROM, gene, locus_snp.shape[1], cis_snp_h2, cis_snp_h2_se, logL, len(samples_to_keep)]))\n",
    "            print(word)\n",
    "            \n",
    "        else:\n",
    "            print( \"\\t\".join(map(str, [CHROM, gene, best_str_start, locus_snp.shape[1], cis_snp_h2, cis_snp_h2_se,\\\n",
    "                                               cis_str_h2, cis_str_h2_se, logL, len(samples_to_keep), pval]))+\"\\n\")  #Figure out this , len(cis_str_h2_null)       \n",
    "        break\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(617, 29)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cis_snps.loc[cis_snps['start']==43766426]\n",
    "#estr_results[estr_results[\"gene\"]==ensgene].sort_values(\"p.wald\")\n",
    "locus_snp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
