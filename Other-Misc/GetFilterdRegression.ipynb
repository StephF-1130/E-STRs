{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with chr 1  ...\n",
      "Done with chr X  ...\n",
      "Done with chr Y  ...\n",
      "done...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                              GGTGGTGGTGGGGGCGGTGGGGGTGGTG\n",
       "1                                              GTGTGTGTGTGT\n",
       "2                                         GGTTTTTTTTTTTTTTT\n",
       "3         TGTGTCTCCCTCTCTCTCTCTCTCTCTCTCTCTCATTTCTCTCTAT...\n",
       "4                                            AAAAAAAAAAAAAA\n",
       "5                                      CCATTAAAAAAAAAAAAAAA\n",
       "6                                 AAAGTTTTTTTTTCTTTTTTTTTTT\n",
       "7                               ATAAAAAATAAATAAATAAATAAAAAC\n",
       "8                                             AAAAAAAAAAAAA\n",
       "9                                           AAATAAATAAATAAA\n",
       "10                                     TTTTTTTTTTTTTTTTTTTG\n",
       "11                                       GCAAAAAAAAAAAAAAAA\n",
       "12                AAATAAATAAATAAATAAATAAATAAATAAATTAAATAAAT\n",
       "13                                          TTTTTTTTTTTTTTG\n",
       "14                                AAAAAGAAAAAGAAAAAAAGAAAAA\n",
       "15                       AAAAGCAAAACAAACAAACAAACAAAACAAAACA\n",
       "16                        GGTGTGTGTGTGTGTGTGTGTGTGTGTGTGTGT\n",
       "17        TTTCCTTTCCTTTCCTTGCTCTTCTTTCTCTCCTATTGCTTTCCTT...\n",
       "18                                         TCAAAAAAAAAAAAAG\n",
       "19                                             AAAAAAAAAAAT\n",
       "20                                       TTTTTTTTCTTTTTTTTT\n",
       "21                                ACACACATACACACACACACACACA\n",
       "22                                            TGAAAAAAAAAAA\n",
       "23                                          TTTTTTTTTTTTTTT\n",
       "24                                      CACCCTTTTTTTTTTTTTT\n",
       "25                                  TCAAAAAAAAAAAAAAAAAAAAA\n",
       "26                              GACTTCAAAAAAAAAAAAAAAAAAAAA\n",
       "27                                         ACACACACACAAACAC\n",
       "28                                         TTTTTTTTTCTTTTTT\n",
       "29                                         TCAAAAAAAAAAAAAT\n",
       "                                ...                        \n",
       "210168                                 AAAAAAAAAATTAAAAAAAA\n",
       "210169                                     TCAAAAAAAAAAAACC\n",
       "210170               ATTTTATTTTATTTTACTTCATTTATTTATTCTATTTT\n",
       "210171                                      TTTTTTATTTTTTTT\n",
       "210172                                 TTATTATTATTATCATTATT\n",
       "210173                AATCGAATCAAATCAAATCAAATCAAATCACATCAAA\n",
       "210174    GCTGAAGTGGAGTGGAGTGGAATGTATTGGGTGGAATGGAATAGAA...\n",
       "210175    GGTGAAGTGGAGTGGAGTGGAATGTATTGGGTGGAATGGAATAGAA...\n",
       "210176    GAATGGAATGGAATGGTATGGAACGTACTGGAATGGAATGGATAAG...\n",
       "210177                                AGTGGAGCGGAGTGGAGTGGA\n",
       "210178                   GAGTGGATTGGAGTGGACTGGAGTGGAATGGAAA\n",
       "210179    GTGGAGTGGAGTAGAGTGGAATGGGTTGGAGTTGAATGCAGAGGAC...\n",
       "210180    AATGGAGTGGAGTGGAATCGAATGTAATGGAATGGAATGGAACGTA...\n",
       "210181                                TGGAATGGAATGGAATGGAAT\n",
       "210182    AGTGGAGTGGAAAGGAATGGAATGGAATGGAATGGAATGGAATGGA...\n",
       "210183    TTTTGCATTCCATTACATTCTATGACATTCGATTCCGTTTCATTGC...\n",
       "210184                                       AAAAAAAAAAAAAT\n",
       "210185                                          AAAAAAAAAAA\n",
       "210186                                   AAAAGAAAAAAAAAATTC\n",
       "210187                                   TTTTTTTTTTTCTTTTTT\n",
       "210188                                      AAAAAGAAAAAAAAA\n",
       "210189          ACACACACACACACACACACACACACACACACACACACACAAG\n",
       "210190                          TGTCTCAAAAAAAAGAAAAAGAAAAAA\n",
       "210191                                       AAAAAAAAAAAAAC\n",
       "210192                               AAAAAAAAAAAAAAAAAAGGAG\n",
       "210193                             GTGCACACACACACACACACATAT\n",
       "210194                                TTTTTTTTTTTTTTTTGAGAC\n",
       "210195                                      AAAAAAATAAAAAAA\n",
       "210196               CAAAAAACAAAAAACAAACAAACAAACAAACAAACAAA\n",
       "210197                             GTTATTTTTCTTTCTTTCTTTTTA\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Use file.txt from this code to remove homopolymers from 5th column\n",
    "import vcf\n",
    "import pandas as pd\n",
    "\n",
    "#chrs = [x for x in range(1,23,1)]\n",
    "#chrs.append('X') ; chrs.append('Y')\n",
    "Out=open('file.txt','w')\n",
    "#VCF extracting the ref and alt alleles\n",
    "for i in chrs:\n",
    "#    Collecting alleles\n",
    "    strfile= \"/storage/szfeupe/Runs/GTEx_estr/STRs_No_Missing_genotypes/STR_filter.chr\"+str(i)+\".vcf.gz\"\n",
    "    STRs = vcf.Reader(filename=strfile)\n",
    "    #print \"Chr\",i,' ...'\n",
    "    for record in STRs:\n",
    "        Data = [record.CHROM, record.POS, record.REF, record.ALT, record.INFO['PERIOD'], record.INFO['REFAC']]\n",
    "        Out.write(\"\\t\".join([str(b) for b in Data])+'\\n')\n",
    "    print (\"Done with chr\",i,' ...')\n",
    "Out.close()\n",
    "see=pd.read_csv('file.txt', sep='\\t', header=None)    \n",
    "print (\"done...\")\n",
    "see[2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##This code will remove homopolymer and least polymorphic sitesfrom linear regression analysis output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import vcf\n",
    "import os\n",
    "\n",
    "Input='/storage/szfeupe/Runs/GTEx_estr/Analysis_by_Tissue/Esophagus-Mucosa/SNP_Analysis/' #CHANGE HERE!!!\n",
    "print(Input)\n",
    "# STR size unit file\n",
    "Reg='/storage/szfeupe/data/Regions_HipSTR_reference.hg19.bed'\n",
    "regions=pd.read_csv(Reg, sep='\\t', header=None)\n",
    "                #ID addition\n",
    "regions[1]= regions[1].astype('str')\n",
    "regions['ID'] = regions[0]+'_'+ regions[1]\n",
    "print('HipSTR regions: ',regions.shape)\n",
    "#Remove homopolymers\n",
    "poly=regions.loc[regions[3]!=1]\n",
    "print('Non homopolymer regions: ',poly.shape)\n",
    "\n",
    "# Low heterozygosity sites\n",
    "strfile= \"/storage/szfeupe/Runs/GTEx_estr/least_polymorphic_sites.tsv\"\n",
    "L_pol = pd.read_csv(strfile, sep='\\t')\n",
    "                #ID addition\n",
    "L_pol['POS']= L_pol['POS'].astype('str')\n",
    "L_pol['ID'] = L_pol['chrom']+'_'+L_pol['POS']\n",
    "print('Regions of low heterozygosity: ',L_pol.shape)\n",
    "\n",
    "# Linear regression output\n",
    "linreg = pd.read_csv(Input+'/Lin_Reg_Out', sep='\\t')\n",
    "#linreg = pd.read_csv(Input+'/Lin_Reg_Out_perm', sep='\\t')\n",
    "                #ID addition\n",
    "linreg['str.start']= linreg['str.start'].astype('str')\n",
    "linreg['ID'] = linreg['chrom']+'_'+linreg['str.start']\n",
    "print('All sites considered for LR: ',linreg.shape)\n",
    "\n",
    "#-------\n",
    "chrs = [i for i in range(1,23)]\n",
    "chrs.append('X') ; chrs.append('Y')\n",
    "#---------\n",
    "index=['0']\n",
    "Out = pd.DataFrame(index=index, columns=linreg.columns)\n",
    "#------------\n",
    "\n",
    "\n",
    "#LR Cleanup\n",
    "for i in chrs:\n",
    "#    print('..............chr',i)\n",
    "    Reg= poly.loc[poly[0]=='chr'+str(i)]\n",
    "    ID=list(Reg['ID']) ; IDs = []\n",
    " #Here we want to include any STR starting within 5bps of the start point\n",
    "    for elt in ID:\n",
    "        e = int(elt.split('_')[1])  ; x=elt.split('_')[0]\n",
    "        f=[str(e), str(e+1), str(e+2),str(e+3),str(e+4),str(e+5), str(e-2),str(e-3),str(e-4),str(e-1)]   #+5bases\n",
    "        f=[x+'_'+p for p in f]\n",
    "        IDs += f  \n",
    " #List of IDs to consider completed    \n",
    "    LIN = linreg.loc[linreg['chrom']=='chr'+str(i)]\n",
    "    POL = L_pol.loc[L_pol['chrom']=='chr'+str(i)]\n",
    "    \n",
    "#Remove homopolymers regions from regression\n",
    "    Filt1 = LIN.loc[LIN['ID'].isin(IDs)]     #>=Reg[1] and LIN['str.start']<=Reg[2]]\n",
    "\n",
    "#Remove least polymorphic sites from regression\n",
    "#least polymorphic sites (Het ziygosity <0.3)\n",
    "    Filt2 = Filt1.loc[Filt1['ID'].isin(list(POL['ID']))==False]\n",
    "#    print(LIN.shape, Filt1.shape,Filt2.shape[0])\n",
    "\n",
    "#Output\n",
    "    frames = [Out, Filt2]\n",
    "    Out = pd.concat(frames)\n",
    "\n",
    "Out1=Out.drop('0')\n",
    "Out1=Out1.drop('Unnamed: 0', 1)\n",
    "Out1.to_csv(Input+'/Lin_Reg_OutFin.txt', sep='\\t', index=False)\n",
    "Out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esophagus-Mucosa/SNP_Analysis  variants ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.4/site-packages/ipykernel/__main__.py:10: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10289721, 12)   to   (16211, 12)\n",
      "16211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.4/site-packages/ipykernel/__main__.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16211, 6) \t (16211, 14)\n",
      "16211  total tests...  11413  pvalues were reduced to 1\n",
      "\n",
      "691 \t qval<=0.1\n",
      "556 \t qval<=0.05\n",
      "379 \t qval<0.01\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Simpler version of FDR correction \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import collections\n",
    "def fdrcorrection(tissue):\n",
    "    print(tissue, ' variants ...')\n",
    "#Get most signif. variant by gene from linear reg STRs\n",
    "    LR1=pd.read_csv(\"/storage/szfeupe/Runs/GTEx_estr/Analysis_by_Tissue/\"+ tissue+ \"/Lin_Reg_OutFin.txt\", '\\t')\n",
    "    LR0 = LR1.sort(\"p.wald\").groupby(\"gene\", as_index=False).first()     \n",
    "    print(LR1.shape, '  to  ', LR0.shape)\n",
    "\n",
    "#Add counts by genes\n",
    "    counts=pd.DataFrame({'cts' : LR1.groupby([\"gene\"]).size()})    ## This is the count by genes\n",
    "    genes = list(LR0['gene'])\n",
    "    LR0['NTEST']= list(counts.loc[genes]['cts'])\n",
    "    print (len(counts.loc[genes]['cts']))\n",
    "    \n",
    "#Minor adjustment\n",
    "    #(1) min_pval* #test\n",
    "    LR0['AD.pval']=LR0['p.wald']*LR0['NTEST']\n",
    "    #(2) if AD_pval>1 => AD_pval=1\n",
    "    LR0['AD.pval'][LR0['AD.pval']>1] = 1\n",
    "    \n",
    "#Save pval in file and FDR correct\n",
    "    LR0['AD.pval'].to_csv('pvalues.txt', sep='\\n', index=False)\n",
    "    Tell = subprocess.call(\"/home/szfeupe/projects/GTEX_eSTRs/gtex-estrs/Scripts/fdr-correct.r\")\n",
    "    \n",
    "#FDR corrected... add to dataframe\n",
    "    Qval=pd.read_csv('/home/szfeupe/projects/GTEX_eSTRs/gtex-estrs/Scripts/qvalues.txt', sep=' ')\n",
    "    print (Qval.shape, '\\t', LR0.shape)\n",
    "    LR0['qvalue']=list(Qval['qvalue'])\n",
    "    LR0['significant']=list(Qval['significant'])\n",
    "    \n",
    "#Header arrangement\n",
    "    Head=['gene','chrom','str.id','str.start','NTEST','p.wald','AD.pval','qvalue','significant','beta','beta.se']\n",
    "    Out=LR0[Head]\n",
    "    Out.to_csv(\"/storage/szfeupe/Runs/GTEx_estr/Analysis_by_Tissue/\"+tissue+'/PQValue.tsv', sep='\\t', index=False)\n",
    "\n",
    "    S=LR0['AD.pval']\n",
    "    print(len(S),' total tests... ', len(S[S>=1]) , ' pvalues were reduced to 1\\n')\n",
    "    print(len(Qval[Qval['qvalue'] <=0.1]),'\\t qval<=0.1')\n",
    "    print(len(Qval[Qval['qvalue'] <=0.05]),'\\t qval<=0.05')\n",
    "    print(len(Qval[Qval['qvalue'] <=0.01]),'\\t qval<0.01\\n')\n",
    "#   print('Original linear reg. tests counts\\n',LR1.groupby('chrom').size())\n",
    "#   print('After FDR correction test counts\\n',LR0.groupby('chrom').size())    \n",
    "\n",
    "    return()\n",
    "\n",
    "fdrcorrection('Esophagus-Mucosa/SNP_Analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15520, 13) (16211, 13)\n",
      "(15520, 13) (16211, 13) 459\n",
      "(15520, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16211, 11)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###This code prepares inputs for heritability test\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "In = '/storage/szfeupe/Runs/GTEx_estr/Analysis_by_Tissue/Esophagus-Mucosa/'\n",
    "\n",
    "#estrs\n",
    "estr = pd.read_csv(In+'PQValue.tsv', sep=\"\\t\")\n",
    "#esnps\n",
    "esnp = pd.read_csv(In+'SNP_Analysis/PQValue.tsv', sep='\\t')\n",
    "#renaming columns\n",
    "estr['qval.gene']=estr['qvalue']\n",
    "esnp['qval.gene']=esnp['qvalue']\n",
    "estr['pvalue']=estr['AD.pval']\n",
    "esnp['pvalue']=esnp['AD.pval']\n",
    "print(estr.shape, esnp.shape)\n",
    "\n",
    "estr=estr.loc[estr['gene'].isin(list(esnp['gene']))]\n",
    "print(estr.shape, esnp.shape, len(estr.loc[estr['qvalue']<=0.1]))\n",
    "\n",
    "be=[1]*len(estr)\n",
    "estr['best_str'] = be\n",
    "be=[1]*len(esnp)\n",
    "esnp['best_str'] = [1]*len(esnp)\n",
    "Head=['gene', 'chrom', 'str.id', 'str.start', 'NTEST', 'beta','p.wald', 'best_str', 'qval.gene','significant','pvalue']\n",
    "wbsnp=esnp.loc[:,Head]\n",
    "wbstr=estr.loc[:,Head]\n",
    "wbstr.to_csv(In+'HH/estr_results', sep='\\t')\n",
    "wbsnp.to_csv(In+'HH/esnp_results', sep='\\t')\n",
    "print(wbstr.shape)\n",
    "wbsnp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#(182156, 14) out of 1346324 #--41333\n",
    "import pandas as pd\n",
    "\n",
    "Input='/storage/szfeupe/Runs/GTEx_estr/Analysis_by_Tissue/Artery-Tibial/' #CHANGE HERE!!!\n",
    "\n",
    "# STR size unit file\n",
    "Reg='/storage/szfeupe/data/Regions_HipSTR_reference.hg19.bed'\n",
    "regions=pd.read_csv(Reg, sep='\\t', header=None)\n",
    "#ID addition\n",
    "regions[1]= regions[1].astype('str')\n",
    "regions['ID'] = regions[0]+'_'+ regions[1]\n",
    "print(regions.shape)\n",
    "check=pd.read_csv(Input+'/Lin_Reg_Out', sep='\\t')\n",
    "check['str.start']= check['str.start'].astype('int')\n",
    "check['str.start']= check['str.start'].astype('str')\n",
    "check['ID'] = check['chrom']+'_'+check['str.start']\n",
    "print(check.shape)\n",
    "\n",
    "Homop=regions.loc[regions[3]==1]\n",
    "Homop[1]= Homop[1].astype('str')\n",
    "Homop['ID'] = Homop[0]+'_'+ Homop[1]\n",
    "\n",
    "print(Homop.shape)\n",
    "\n",
    "\n",
    "Missed = check.loc[check['ID'].isin(list(regions['ID']))]\n",
    "Missed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/szfeupe/Runs/GTEx_estr/Analysis_by_Tissue/Cells-Transformedfibroblasts/SNP_Analysis/ \n",
      " (9766340, 13)\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
      "1  Done  (919571, 13) \t (919543, 13) \t (918379, 13) \t (918380, 13)\n",
      "2  Done  (668690, 13) \t (668670, 13) \t (667918, 13) \t (1586298, 13)\n",
      "3  Done  (595685, 13) \t (595666, 13) \t (595070, 13) \t (2181368, 13)\n",
      "4  Done  (456948, 13) \t (456939, 13) \t (456507, 13) \t (2637875, 13)\n",
      "5  Done  (475851, 13) \t (475846, 13) \t (475453, 13) \t (3113328, 13)\n",
      "6  Done  (652426, 13) \t (652419, 13) \t (651720, 13) \t (3765048, 13)\n",
      "7  Done  (511925, 13) \t (511912, 13) \t (511334, 13) \t (4276382, 13)\n",
      "8  Done  (395173, 13) \t (395158, 13) \t (394721, 13) \t (4671103, 13)\n",
      "9  Done  (407115, 13) \t (407108, 13) \t (406739, 13) \t (5077842, 13)\n",
      "10  Done  (417027, 13) \t (417017, 13) \t (416491, 13) \t (5494333, 13)\n",
      "11  Done  (531433, 13) \t (531414, 13) \t (530812, 13) \t (6025145, 13)\n",
      "12  Done  (523343, 13) \t (523320, 13) \t (522679, 13) \t (6547824, 13)\n",
      "13  Done  (204583, 13) \t (204581, 13) \t (204386, 13) \t (6752210, 13)\n",
      "14  Done  (313136, 13) \t (313132, 13) \t (312733, 13) \t (7064943, 13)\n",
      "15  Done  (298809, 13) \t (298806, 13) \t (298447, 13) \t (7363390, 13)\n",
      "16  Done  (416311, 13) \t (416308, 13) \t (415890, 13) \t (7779280, 13)\n",
      "17  Done  (501223, 13) \t (501206, 13) \t (500423, 13) \t (8279703, 13)\n",
      "18  Done  (183506, 13) \t (183506, 13) \t (183337, 13) \t (8463040, 13)\n",
      "19  Done  (680310, 13) \t (680301, 13) \t (679837, 13) \t (9142877, 13)\n",
      "20  Done  (257398, 13) \t (257390, 13) \t (257009, 13) \t (9399886, 13)\n",
      "21  Done  (122633, 13) \t (122630, 13) \t (122508, 13) \t (9522394, 13)\n",
      "22  Done  (233244, 13) \t (233236, 13) \t (232921, 13) \t (9755315, 13)\n",
      "X  Done  (0, 13) \t (0, 13) \t (0, 13) \t (9755315, 13)\n",
      "Y  Done  (0, 13) \t (0, 13) \t (0, 13) \t (9755315, 13)\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "##This code is specific for SNP data\n",
    "##It will remove SNPs that fall in homopolymer and least polymorphic sites from linear regression analysis output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import vcf\n",
    "import os\n",
    "\n",
    "Input='/storage/szfeupe/Runs/GTEx_estr/Analysis_by_Tissue/Cells-Transformedfibroblasts/SNP_Analysis/'    #Artery-Tibial/SNP_Analysis/'\n",
    "\n",
    "linreg = pd.read_csv(Input+'/Lin_Reg_Out', sep='\\t')\n",
    "#linreg = pd.read_csv(Input+'/Lin_Reg_Out_perm', sep='\\t')\n",
    "\n",
    "print (Input, '\\n',linreg.shape)\n",
    "\n",
    "strfile= \"/storage/szfeupe/Runs/GTEx_estr/least_polymorphic_sites.tsv\"\n",
    "L_pol = pd.read_csv(strfile, sep='\\t')\n",
    "\n",
    "chrs = [i for i in range(1,23)]\n",
    "print(chrs)\n",
    "chrs.append('X') ; chrs.append('Y')\n",
    "\n",
    "index=['0']\n",
    "Out = pd.DataFrame(index=index, columns=linreg.columns)\n",
    "\n",
    "Reg='/storage/szfeupe/data/Regions_HipSTR_reference.hg19.bed'\n",
    "regions=pd.read_csv(Reg, sep='\\t', header=None)\n",
    "poly=regions.loc[regions[3]==1]\n",
    "#LR Cleanup\n",
    "for i in chrs:\n",
    "    \n",
    "#   Remove Homoploymers\n",
    "    Homopoly = poly.loc[poly[0]=='chr'+str(i)]\n",
    "    LIN = linreg.loc[linreg['chrom']=='chr'+str(i)]\n",
    "    FIL = LIN.loc[LIN['str.start'].isin(list(Homopoly[1]))==False]\n",
    "\n",
    "#    Open least polymorphic sites (Het ziygosity <0.3)\n",
    "    POL = L_pol.loc[L_pol['chrom']=='chr'+str(i)]\n",
    "    Het = list(POL['POS'])\n",
    "    Hets = [[e, e+1, e+2,e+3,e+4,e+5,e+6] for e in Het]\n",
    "    Het = sum(Hets, [])\n",
    "#    Remove those sites\n",
    "    FIL_h = FIL.loc[FIL['str.start'].isin(Het)==False]\n",
    "\n",
    "    \n",
    "#   Sum it up and outout   \n",
    "    frames = [Out, FIL_h]\n",
    "    Out = pd.concat(frames)\n",
    "\n",
    "    print(i,' Done ',LIN.shape,'\\t', FIL.shape, '\\t', FIL_h.shape,'\\t',Out.shape)\n",
    "\n",
    "Out1=Out.drop('0')\n",
    "Out1=Out1.drop('Unnamed: 0', 1)\n",
    "Out1.to_csv(Input+'/Lin_Reg_OutFin.txt', sep='\\t', index=False)\n",
    "#Out1.to_csv(Input+'/Lin_Reg_Out_permFinal.txt', sep='\\t', index=False)  #869845---769487\n",
    "print('End')\n",
    "\n",
    "####After this Script, plot the qqplot and then FDR correction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
